{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n",
      "['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']\n",
      "9\n",
      "65\n",
      "3885\n",
      "39774\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.json\") as f:\n",
    "    datastore = json.loads(f.read())\n",
    "f.close()\n",
    "with open(\"test.json\") as f:\n",
    "    test = json.loads(f.read())\n",
    "f.close()\n",
    "print(type(datastore[0]))\n",
    "print(datastore[0])\n",
    "print(datastore[0]['ingredients'])\n",
    "print(len(datastore[0]['ingredients']))\n",
    "length = len(datastore)\n",
    "length1 = len(test)\n",
    "max = 0\n",
    "pos = 0\n",
    "for x in range(length):\n",
    "    if(len(datastore[x]['ingredients']) > max):\n",
    "        max = len(datastore[x]['ingredients'])\n",
    "        pos = x\n",
    "print(max)\n",
    "print(datastore[pos]['id'])\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "cuisine = []\n",
    "ingre = []\n",
    "full = []\n",
    "for i in range(length):\n",
    "    cuisine.append(datastore[i]['cuisine'])\n",
    "    for j in range(len(datastore[i]['ingredients'])):\n",
    "        ingre.append(datastore[i]['ingredients'][j])\n",
    "    li = [y for y in ingre]\n",
    "    li = \",\".join(map(str, li))\n",
    "    full.append(li)\n",
    "    ingre = []\n",
    "    #if(i == 5000):\n",
    "    #    break\n",
    "    if(i%5000 == 0):\n",
    "        print(i)\n",
    "df = pd.DataFrame({'cuisine':cuisine,'ingredients':full})\n",
    "#print(df.head())\n",
    "#df.groupby('cuisine').cuisine.count().plot.bar(ylim=0)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cuisine                                        ingredients\n",
      "0        greek  romaine lettuce,black olives,grape tomatoes,ga...\n",
      "1  southern_us  plain flour,ground pepper,salt,tomatoes,ground...\n",
      "2     filipino  eggs,pepper,salt,mayonaise,cooking oil,green c...\n",
      "3       indian                     water,vegetable oil,wheat,salt\n",
      "4       indian  black pepper,shallots,cornflour,cayenne pepper...\n",
      "['brazilian' 'british' 'cajun_creole' 'chinese' 'filipino' 'french'\n",
      " 'greek' 'indian' 'irish' 'italian' 'jamaican' 'japanese' 'korean'\n",
      " 'mexican' 'moroccan' 'russian' 'southern_us' 'spanish' 'thai'\n",
      " 'vietnamese']\n",
      "brazilian\n",
      "{'brazilian': 0, 'british': 1, 'cajun_creole': 2, 'chinese': 3, 'filipino': 4, 'french': 5, 'greek': 6, 'indian': 7, 'irish': 8, 'italian': 9, 'jamaican': 10, 'japanese': 11, 'korean': 12, 'mexican': 13, 'moroccan': 14, 'russian': 15, 'southern_us': 16, 'spanish': 17, 'thai': 18, 'vietnamese': 19}\n",
      "   cuisine                                        ingredients\n",
      "0        6  romaine lettuce,black olives,grape tomatoes,ga...\n",
      "1       16  plain flour,ground pepper,salt,tomatoes,ground...\n",
      "2        4  eggs,pepper,salt,mayonaise,cooking oil,green c...\n",
      "3        7                     water,vegetable oil,wheat,salt\n",
      "4        7  black pepper,shallots,cornflour,cayenne pepper...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "df1 = df.copy()\n",
    "cuis = np.unique(df1['cuisine'].values)\n",
    "print(cuis)\n",
    "print(cuis[0])\n",
    "b = {cuis[i]:i for i in range(len(cuis))}\n",
    "print(b)\n",
    "df1 = df1.replace({'cuisine':b})\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romaine lettuce,black olives,grape tomatoes,garlic,pepper,purple onion,seasoning,garbanzo beans,feta cheese crumbles\n",
      "(39774, 17927)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,norm='l2',\\\n",
    "                       encoding='latin-1',ngram_range=(1,2))\n",
    "print(df1['ingredients'][0])\n",
    "features = tfidf.fit_transform(df1.ingredients).toarray()\n",
    "labels = df1['cuisine']\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N = 2\\nfor i in range(len(cuis)):\\n    features_chi2 = chi2(features,labels == i)\\n    indices = np.argsort(features_chi2[0])\\n    features_names = np.array(tfidf.get_feature_names())[indices]\\n    unigrams = [v for v in features_names if len(v.split(\\',\\')) == 1]\\n    bigrams = [v for v in features_names if len(v.split(\\',\\')) == 2]\\n    print(\"# \\'{}\\'\".format(cuis[i]))\\n    print(\"  . Most correlated unigrams:\\n. {}\".          format(\\'\\n. \\'.join(unigrams[-N:])))\\n    print(\"  . Most correlated bigrams:\\n. {}\".          format(\\'\\n. \\'.join(bigrams[-N:])))\\n    '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''N = 2\n",
    "for i in range(len(cuis)):\n",
    "    features_chi2 = chi2(features,labels == i)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    features_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in features_names if len(v.split(',')) == 1]\n",
    "    bigrams = [v for v in features_names if len(v.split(',')) == 2]\n",
    "    print(\"# '{}'\".format(cuis[i]))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".\\\n",
    "          format('\\n. '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".\\\n",
    "          format('\\n. '.join(bigrams[-N:])))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(df1['ingredients'],\\\n",
    "                 df1['cuisine'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "lgr = LogisticRegression(random_state=0).fit(X_train_tfidf, y_train)\n",
    "lsvc = LinearSVC().fit(X_train_tfidf,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plain flour', 'ground pepper', 'salt', 'tomatoes', 'ground black pepper', 'thyme', 'eggs', 'green tomatoes', 'yellow corn meal', 'milk', 'vegetable oil']\n",
      "plain flour,ground pepper,salt,tomatoes,ground black pepper,thyme,eggs,green tomatoes,yellow corn meal,milk,vegetable oil\n",
      "['southern_us']\n"
     ]
    }
   ],
   "source": [
    "str1 = datastore[1]['ingredients']\n",
    "print(str1)\n",
    "str1 = \",\".join(map(str, str1))\n",
    "print(str1)\n",
    "print( cuis[(clf.predict(count_vect.transform([str1])))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False) : [0.32921128 0.32649263]\n",
      "\n",
      "\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) : [0.77771075 0.77023289]\n",
      "\n",
      "\n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) : [0.60267431 0.60696142]\n",
      "\n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) : [0.75202332 0.74739701]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CV = 1\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    accuracy = cross_val_score(model,features,labels,\\\n",
    "                            scoring='accuracy',cv=2)\n",
    "    print(str(model),\":\",accuracy)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "      id                                        ingredients\n",
      "0  18009  baking powder,eggs,all-purpose flour,raisins,m...\n",
      "1  28583  sugar,egg yolks,corn starch,cream of tartar,ba...\n",
      "2  41580  sausage links,fennel bulb,fronds,olive oil,cub...\n",
      "3  29752  meat cuts,file powder,smoked sausage,okra,shri...\n",
      "4  35687  ground black pepper,salt,sausage casings,leeks...\n",
      "baking powder,eggs,all-purpose flour,raisins,milk,white sugar\n",
      "\n",
      "\n",
      "\n",
      "['baking powder,eggs,all-purpose flour,raisins,milk,white sugar', 'sugar,egg yolks,corn starch,cream of tartar,bananas,vanilla wafers,milk,vanilla extract,toasted pecans,egg whites,light rum']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          cuisine     id\n",
      "0   [southern_us]  18009\n",
      "1   [southern_us]  28583\n",
      "2       [italian]  41580\n",
      "3  [cajun_creole]  29752\n",
      "4       [italian]  35687\n",
      "        cuisine     id\n",
      "0   southern_us  18009\n",
      "1   southern_us  28583\n",
      "2       italian  41580\n",
      "3  cajun_creole  29752\n",
      "4       italian  35687\n"
     ]
    }
   ],
   "source": [
    "id1 = []\n",
    "ingre1 = []\n",
    "full1 = []\n",
    "for i in range(length1):\n",
    "    id1.append(test[i]['id'])\n",
    "    for j in range(len\n",
    "                   (test[i]['ingredients'])):\n",
    "        ingre1.append(test[i]['ingredients'][j])\n",
    "    li1 = [y for y in ingre1]\n",
    "    li1 = \",\".join(map(str, li1))\n",
    "    full1.append(li1)\n",
    "    ingre1 = []\n",
    "    #if(i == 5000):\n",
    "    #    break\n",
    "    if(i%5000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "full2 = []\n",
    "for k in range(len(full1)):\n",
    "    full2.append(full1[k])\n",
    "\n",
    "df2 = pd.DataFrame({'id':id1,'ingredients':full1})\n",
    "print(df2.head())\n",
    "print(df2['ingredients'][0])\n",
    "ans = []\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(full2[:2])\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "for k in range(len(full1)):\n",
    "    ans.append((cuis[(\\\n",
    "    clf.predict(count_vect.transform([full1[k]])))]))\n",
    "\n",
    "out = pd.DataFrame({'id':df2['id'], 'cuisine':ans})\n",
    "'''df2['ingredients'] = \",\".join(map(str, df2['ingredients']))\n",
    "print(df2.head())\n",
    "ans = pd.DataFrame(columns=['cuisine'])\n",
    "k = 0\n",
    "print(df2['ingredients'][0])\n",
    "print(\"\\t\\t\\tTesting\")'''\n",
    "'''for i in df2['ingredients']:\n",
    "    temp = pd.DataFrame(columns=['cuisine'])\n",
    "    temp['cuisine'] = (cuis[(\\\n",
    "    clf.predict(count_vect.transform([i])))])\n",
    "    #print(i)\n",
    "    print(temp)\n",
    "    ans = ans.append(temp)\n",
    "    k+=10\n",
    "    if(k == 1):\n",
    "        break'''\n",
    "#print(ans)\n",
    "print(out.head())\n",
    "out['cuisine'] = out['cuisine'].str[0]\n",
    "print(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"submission.csv\"\n",
    "out.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "      id                                        ingredients\n",
      "0  18009  baking powder,eggs,all-purpose flour,raisins,m...\n",
      "1  28583  sugar,egg yolks,corn starch,cream of tartar,ba...\n",
      "2  41580  sausage links,fennel bulb,fronds,olive oil,cub...\n",
      "3  29752  meat cuts,file powder,smoked sausage,okra,shri...\n",
      "4  35687  ground black pepper,salt,sausage casings,leeks...\n",
      "baking powder,eggs,all-purpose flour,raisins,milk,white sugar\n",
      "\n",
      "\n",
      "\n",
      "['baking powder,eggs,all-purpose flour,raisins,milk,white sugar', 'sugar,egg yolks,corn starch,cream of tartar,bananas,vanilla wafers,milk,vanilla extract,toasted pecans,egg whites,light rum']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          cuisine     id\n",
      "0       [british]  18009\n",
      "1   [southern_us]  28583\n",
      "2       [italian]  41580\n",
      "3  [cajun_creole]  29752\n",
      "4       [italian]  35687\n",
      "        cuisine     id\n",
      "0       british  18009\n",
      "1   southern_us  28583\n",
      "2       italian  41580\n",
      "3  cajun_creole  29752\n",
      "4       italian  35687\n"
     ]
    }
   ],
   "source": [
    "id1 = []\n",
    "ingre1 = []\n",
    "full1 = []\n",
    "for i in range(length1):\n",
    "    id1.append(test[i]['id'])\n",
    "    for j in range(len\n",
    "                   (test[i]['ingredients'])):\n",
    "        ingre1.append(test[i]['ingredients'][j])\n",
    "    li1 = [y for y in ingre1]\n",
    "    li1 = \",\".join(map(str, li1))\n",
    "    full1.append(li1)\n",
    "    ingre1 = []\n",
    "    #if(i == 5000):\n",
    "    #    break\n",
    "    if(i%5000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "full2 = []\n",
    "for k in range(len(full1)):\n",
    "    full2.append(full1[k])\n",
    "\n",
    "df2 = pd.DataFrame({'id':id1,'ingredients':full1})\n",
    "print(df2.head())\n",
    "print(df2['ingredients'][0])\n",
    "ans = []\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(full2[:2])\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "for k in range(len(full1)):\n",
    "    ans.append((cuis[(\\\n",
    "    lgr.predict(count_vect.transform([full1[k]])))]))\n",
    "\n",
    "out = pd.DataFrame({'id':df2['id'], 'cuisine':ans})\n",
    "'''df2['ingredients'] = \",\".join(map(str, df2['ingredients']))\n",
    "print(df2.head())\n",
    "ans = pd.DataFrame(columns=['cuisine'])\n",
    "k = 0\n",
    "print(df2['ingredients'][0])\n",
    "print(\"\\t\\t\\tTesting\")'''\n",
    "'''for i in df2['ingredients']:\n",
    "    temp = pd.DataFrame(columns=['cuisine'])\n",
    "    temp['cuisine'] = (cuis[(\\\n",
    "    clf.predict(count_vect.transform([i])))])\n",
    "    #print(i)\n",
    "    print(temp)\n",
    "    ans = ans.append(temp)\n",
    "    k+=10\n",
    "    if(k == 1):\n",
    "        break'''\n",
    "#print(ans)\n",
    "print(out.head())\n",
    "out['cuisine'] = out['cuisine'].str[0]\n",
    "print(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"submission2.csv\"\n",
    "out.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "      id                                        ingredients\n",
      "0  18009  baking powder,eggs,all-purpose flour,raisins,m...\n",
      "1  28583  sugar,egg yolks,corn starch,cream of tartar,ba...\n",
      "2  41580  sausage links,fennel bulb,fronds,olive oil,cub...\n",
      "3  29752  meat cuts,file powder,smoked sausage,okra,shri...\n",
      "4  35687  ground black pepper,salt,sausage casings,leeks...\n",
      "baking powder,eggs,all-purpose flour,raisins,milk,white sugar\n",
      "\n",
      "\n",
      "\n",
      "['baking powder,eggs,all-purpose flour,raisins,milk,white sugar', 'sugar,egg yolks,corn starch,cream of tartar,bananas,vanilla wafers,milk,vanilla extract,toasted pecans,egg whites,light rum']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          cuisine     id\n",
      "0       [british]  18009\n",
      "1   [southern_us]  28583\n",
      "2       [italian]  41580\n",
      "3  [cajun_creole]  29752\n",
      "4       [italian]  35687\n",
      "        cuisine     id\n",
      "0       british  18009\n",
      "1   southern_us  28583\n",
      "2       italian  41580\n",
      "3  cajun_creole  29752\n",
      "4       italian  35687\n"
     ]
    }
   ],
   "source": [
    "id1 = []\n",
    "ingre1 = []\n",
    "full1 = []\n",
    "for i in range(length1):\n",
    "    id1.append(test[i]['id'])\n",
    "    for j in range(len\n",
    "                   (test[i]['ingredients'])):\n",
    "        ingre1.append(test[i]['ingredients'][j])\n",
    "    li1 = [y for y in ingre1]\n",
    "    li1 = \",\".join(map(str, li1))\n",
    "    full1.append(li1)\n",
    "    ingre1 = []\n",
    "    #if(i == 5000):\n",
    "    #    break\n",
    "    if(i%5000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "full2 = []\n",
    "for k in range(len(full1)):\n",
    "    full2.append(full1[k])\n",
    "\n",
    "df2 = pd.DataFrame({'id':id1,'ingredients':full1})\n",
    "print(df2.head())\n",
    "print(df2['ingredients'][0])\n",
    "ans = []\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(full2[:2])\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "for k in range(len(full1)):\n",
    "    ans.append((cuis[(\\\n",
    "    lsvc.predict(count_vect.transform([full1[k]])))]))\n",
    "\n",
    "out = pd.DataFrame({'id':df2['id'], 'cuisine':ans})\n",
    "'''df2['ingredients'] = \",\".join(map(str, df2['ingredients']))\n",
    "print(df2.head())\n",
    "ans = pd.DataFrame(columns=['cuisine'])\n",
    "k = 0\n",
    "print(df2['ingredients'][0])\n",
    "print(\"\\t\\t\\tTesting\")'''\n",
    "'''for i in df2['ingredients']:\n",
    "    temp = pd.DataFrame(columns=['cuisine'])\n",
    "    temp['cuisine'] = (cuis[(\\\n",
    "    clf.predict(count_vect.transform([i])))])\n",
    "    #print(i)\n",
    "    print(temp)\n",
    "    ans = ans.append(temp)\n",
    "    k+=10\n",
    "    if(k == 1):\n",
    "        break'''\n",
    "#print(ans)\n",
    "print(out.head())\n",
    "out['cuisine'] = out['cuisine'].str[0]\n",
    "print(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"submission3.csv\"\n",
    "out.to_csv(file,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
